# 서버 성능에 대한 기본 지식

---

## 1. 서버 성능 기본 지표

### 1) 응답시간

- Latency Time(대기 시간): 요청이 서버에 도착하여 처리를 시작하기 전, 처리가 완료된 데이터를 클라이언트에게 전달하는 시간
- Processing Time(처리 시간): 서버에서 요청 처리를 시작하여 응답 데이터가 완성될 때까지 걸리는 시간
- Response Time(응답 시간): 대기 시간 + 처리 시간

### 2) 처리량

- TPS(Transaction Per Second): 초당 몇개의 요청을 처리할 수 있는가

### 3) 성능에 대한 표현

- "몇 명의 사용자가 어느 정도의 밀도로 API 요청을 할 때, 서버의 응답 속도 분포는 XX다." 의 형태가 현실적인 표현 방법

## 2. 처리시간을 제외한 처리량을 늘리는 방법

### 1) 앱 서버 갯수 늘리기
   - e.g) 서버 1개 -> 10 TPS ==> 서버 2개 -> 20 TPS
### 2) 쓰레드 풀 & DB 커넥션 풀 늘리기
   - e.g) 쓰레드 풀 10개 -> 10 TPS ==> 쓰레드 풀 20개 -> 20 TPS

- 앱 서버의 처리량은 초반에는 늘어날 수 있지만, 무한정 늘어나지는 않는다. 가장 기본적인 3 Tier 웹 애플리케이션이라고 가정한다면, `Web Server`, `Web Application Server`, `DB` 중 부하 병목지점이 추가로 생기게 된다.
- 이 지점에서 앱 서버의 처리시간 자체를 줄이는 것 자체도 필요하다는 것을 알게 된다.
  - e.g) 처리시간 1초 -> 10 TPS ==> 처리시간 0.5초 -> 20 TPS

> 처리 시간에서 비중이 높은 대상부터 찾아서 줄여야 한다!
> 
> 보통 `DB 연동`, `API 호출`, `데이터 집계 및 계산`, `네트워크 대기시간` 순으로 처리 시간 비중이 높다.

## 3. DB와 관련된 처리 시간 줄이기

### 1) 캐시

### 2) 쿼리 튜닝

### 3) 장비 업그레이드

1. Scale Out(Primary/Replica 등)
2. Scale Up(서버 스펙 업그레이드)

## 4. API 호출과 관련된 처리 시간 줄이기

### 1) 캐시

### 2) 호출 제거

- 직접 외부 서버 호출 대신 메시징 + 비동기 연동을 사용

### 3) 데이터 집계 및 계산 스케줄링

- 미리 계산해서 캐싱 등

### 4) 네트워크 대기시간 줄이기

> 하나의 데이터 패킷이 출발지에서 도착지까지 가는 데 걸리는 시간. 즉, 네트워크나 인터넷 연결의 지연 시간을 나타낸다. - mdn web docs 중

- 대역폭 늘리기: 패킷이 지나가는 통로 늘리기(인프라 측면이라 비용적으로 쉽지 않음)
- 응답 크기 줄이기: 압축 등을 통해 데이터 크기 자체를 줄이기
- 트래픽 분리하기: 이미지, 정적 파일을 CDN을 통해 제공 등

---

### 참고자료
- [최범균 유튜브](https://youtu.be/JJJ4LReZ5q4?si=50MaaykEgnddJpQX)
- [엘리스 유튜브](https://www.youtube.com/watch?v=HSNyJnobBws&t=18s)
- [mdn web docs](https://developer.mozilla.org/ko/docs/Web/Performance/Understanding_latency)